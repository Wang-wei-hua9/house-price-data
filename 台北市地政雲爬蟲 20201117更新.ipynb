{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "松山區    虎林街 資料爬取完成\n",
      "松山區 長安東路二段 資料爬取完成\n",
      "松山區    長春路 資料爬取完成\n",
      "松山區 南京東路三段 資料爬取完成\n",
      "松山區 南京東路五段 資料爬取完成\n",
      "松山區 南京東路四段 資料爬取完成\n",
      "松山區    健康路 資料爬取完成\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=86.0.4240.198)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-be83827d9ef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'全部資料爬取完成'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m \u001b[0mClawler_by_Time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m109\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m109\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;31m# 將爬下來的資料存入字典\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-be83827d9ef6>\u001b[0m in \u001b[0;36mClawler_by_Time\u001b[1;34m(sy, sm, ey, em)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_RoadList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             crawler(district=district, positioning_method='路段', road=r,\n\u001b[1;32m--> 384\u001b[1;33m                     start_year=sy, start_month=sm, end_year=ey, end_month=em)\n\u001b[0m\u001b[0;32m    385\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'全部資料爬取完成'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-be83827d9ef6>\u001b[0m in \u001b[0;36mcrawler\u001b[1;34m(district, positioning_method, road, start_year, start_month, end_year, end_month, transactional_type)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# 選定位方式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     driver.find_element_by_id(\n\u001b[1;32m---> 47\u001b[1;33m         'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_locate').click()\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0moption\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'option'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpositioning_method\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3 20200629\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3 20200629\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3 20200629\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mD:\\anaconda3 20200629\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=86.0.4240.198)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sys\n",
    "import re\n",
    "\n",
    "url = 'https://cloud.land.gov.taipei/ImmPrice/TruePriceA.aspx'  # 台北地政雲網站\n",
    "# webdriver位置(phantomjs)\n",
    "#webdriver_path = 'C:\\\\Program Files\\\\phantomjs-2.1.1-windows\\\\bin\\\\phantomjs.exe'\n",
    "#driver = webdriver.PhantomJS(executable_path=webdriver_path)\n",
    "\n",
    "# webdriver位置(chromedriver)\n",
    "webdriver_path = 'C:\\\\Program Files\\\\Google\\\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(executable_path=webdriver_path)\n",
    "driver.implicitly_wait(120)\n",
    "\n",
    "\n",
    "def crawler(district, positioning_method, road, start_year, start_month, end_year, end_month, transactional_type='房地'):  ###此處有更動###\n",
    "    '''\n",
    "    輸入選擇條件\n",
    "    '''\n",
    "    # 先輸入篩選條件\n",
    "    driver.get(url)  # 連接到台北地政雲不動產價格資訊\\買賣實價查詢網頁\n",
    "    #driver.refresh()\n",
    "\n",
    "    # 選行政區\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_MasterGond').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == district:\n",
    "            option.click()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "\n",
    "    # 選定位方式\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_locate').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == positioning_method:\n",
    "            option.click()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "\n",
    "    # 選路段\n",
    "    element = WebDriverWait(driver, 30).until(expected_conditions.presence_of_element_located(\n",
    "        (By.ID, 'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_txb_GondRoad')))  ###此處有更動###\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_txb_GondRoad').click()  ###此處有更動###\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == road:\n",
    "            option.click()\n",
    "            time.sleep(0.5)\n",
    "            break\n",
    "                \n",
    "    # 選起始年\n",
    "    select = Select(driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionStartYear'))\n",
    "    select.select_by_value(str(start_year))\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # 選起始月\n",
    "    select = Select(driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionStartMonth'))\n",
    "    select.select_by_value(str(start_month).zfill(2))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 選截止年\n",
    "    select = Select(driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionEndYear'))\n",
    "    select.select_by_value(str(end_year))\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # 選截止月\n",
    "    select = Select(driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionEndMonth'))\n",
    "    select.select_by_value(str(end_month).zfill(2))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    '''\n",
    "    # 選起始年月和截止年月產生問題\n",
    "    # 由於原來的選擇方式在選起始年月時是先點開下拉選單後選擇選項\n",
    "    # 在選截止年月時的選擇會覆蓋回起始年月，因為選項種類一致\n",
    "    # 這是因為option選項沒有經過定位造成的\n",
    "    # 所以改用上面的寫法\n",
    "     \n",
    "    # 選起始年    \n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionStartYear').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == str(start_year):  ###此處有更動###\n",
    "            option.click()\n",
    "            time.sleep(0.5)\n",
    "            break\n",
    "    \n",
    "    # 選起始月\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionStartMonth').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == str(start_month).zfill(2):  ###此處有更動###\n",
    "            option.click()\n",
    "            time.sleep(0.5)\n",
    "            break\n",
    "    \n",
    "    # 選截止年\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionEndYear').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == str(end_year):\n",
    "            option.click()\n",
    "            time.sleep(1)\n",
    "            break\n",
    " \n",
    "    # 選截止月\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionEndMonth').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == str(end_month).zfill(2):\n",
    "            option.click()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "    '''        \n",
    "    # 選交易類型\n",
    "    driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_ddl_TransactionType').click()\n",
    "    for option in driver.find_elements_by_tag_name('option'):\n",
    "        if option.text == transactional_type:\n",
    "            option.click()\n",
    "            time.sleep(0.5)\n",
    "            break\n",
    "\n",
    "    # 點選查詢\n",
    "    element = driver.find_element_by_id(\n",
    "        'ContentPlaceHolder1_ContentPlaceHolder1_TruePriceSearch_btn_Search').click()\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    開始爬資料，這裡會有幾種情況\n",
    "    1. 資料只有一頁\n",
    "    2. 資料有很多頁（超過10頁）\n",
    "    3. 資料不超過10頁\n",
    "    4. 查無資料\n",
    "    '''\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 60).until(expected_conditions.presence_of_element_located(\n",
    "                    (By.ID, 'ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice')))\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        table = bs.find(id='ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice')\n",
    "        page_info = table.find('td', {'colspan':'19'})  ###此處有更動###\n",
    "\n",
    "        # 狀況1 資料只有一頁\n",
    "        if page_info == None:\n",
    "            #print('只有一頁')\n",
    "            bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            get_ColumnsData(bs)\n",
    "\n",
    "        # 狀況2 資料有很多頁（超過10頁）\n",
    "        elif re.search('最末頁', str(page_info)) != None:\n",
    "            #print('有最末頁按鈕')\n",
    "            # 等待第一頁資料出來\n",
    "            element = WebDriverWait(driver, 60).until(expected_conditions.presence_of_element_located(\n",
    "                (By.ID, 'ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice')))\n",
    "            bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # 先翻到最末頁確認總頁數\n",
    "            driver.find_element_by_link_text('最末頁').click()\n",
    "            element = WebDriverWait(driver, 60).until(expected_conditions.presence_of_element_located(\n",
    "                (By.LINK_TEXT, '第一頁')))\n",
    "            bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            table = bs.find(\n",
    "                id='ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice')\n",
    "            for row in table.find('td'):\n",
    "                last_page = int([s for s in row.stripped_strings][-1])\n",
    "                # print(last_page)\n",
    "\n",
    "            # 回到第一頁\n",
    "            driver.find_element_by_link_text('第一頁').click()\n",
    "            element = WebDriverWait(driver, 60).until(expected_conditions.presence_of_element_located(\n",
    "                (By.LINK_TEXT, '最末頁')))\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # 從第一頁開始儲存資料\n",
    "            bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            get_ColumnsData(bs)\n",
    "            \n",
    "            # 翻頁繼續儲存資料\n",
    "            now_page = i = 1\n",
    "            while i <= last_page-1:\n",
    "                next_page = i + 1\n",
    "                if next_page == 11:  # 若下一頁為11，點擊'...'的按鈕\n",
    "                    driver.find_element_by_link_text('...').click()\n",
    "                    element = WebDriverWait(driver, 60).until(expected_conditions.element_to_be_clickable(\n",
    "                        (By.LINK_TEXT, '第一頁')))\n",
    "                    time.sleep(1)\n",
    "                    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    get_ColumnsData(bs)\n",
    "\n",
    "                # 若下一頁為[21,31,41,51,61,71,81,91,101,]點擊td[13]的超連接\n",
    "                elif next_page in [21, 31, 41, 51, 61, 71, 81, 91, 101, 111, 121, 131, 141, 151]:\n",
    "                    driver.find_element_by_xpath(\n",
    "                        '//*[@id = \"ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice\"]/tbody/tr[1]/td/table/tbody/tr/td[13]/a').click()\n",
    "                    element = WebDriverWait(driver, 20).until_not(\n",
    "                        expected_conditions.element_to_be_clickable((By.LINK_TEXT, str(next_page))))\n",
    "                    time.sleep(1)    \n",
    "                    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    get_ColumnsData(bs)\n",
    "\n",
    "                else:\n",
    "                    driver.find_element_by_link_text(\n",
    "                        str(next_page)).click()  # 正常換頁\n",
    "                    element = WebDriverWait(driver, 120).until(\n",
    "                        expected_conditions.element_to_be_clickable((By.LINK_TEXT, str(next_page-1))))\n",
    "                    time.sleep(1)\n",
    "                    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    get_ColumnsData(bs)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "        # 狀況3 資料不超過10頁\n",
    "        elif re.search('最末頁', str(page_info)) == None:\n",
    "            #print('無最末頁按鈕')\n",
    "            for row in table.find('td'):\n",
    "                last_page = int([s for s in row.stripped_strings][-1])\n",
    "                # print(last_page)\n",
    "            \n",
    "            # 從第一頁開始儲存資料\n",
    "            bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            get_ColumnsData(bs)\n",
    "\n",
    "            # 翻頁繼續儲存資料\n",
    "            now_page = i = 1\n",
    "            while i <= last_page-1:\n",
    "                next_page = i + 1\n",
    "                driver.find_element_by_link_text(\n",
    "                    str(next_page)).click()  # 正常換頁\n",
    "                #time.sleep(10)\n",
    "                element = WebDriverWait(driver, 60).until(\n",
    "                    expected_conditions.element_to_be_clickable((By.LINK_TEXT, str(next_page-1))))\n",
    "                time.sleep(1)\n",
    "                bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                get_ColumnsData(bs)\n",
    "\n",
    "                i += 1    \n",
    "\n",
    "        print('%s %6s 資料爬取完成' % (district,  road))\n",
    "\n",
    "    except UnexpectedAlertPresentException:\n",
    "        error_info = sys.exc_info()\n",
    "        error_msg = re.findall('\\{.*\\}', str(error_info))[0]\n",
    "        print('%s %6s 爬取遇到錯誤/錯誤訊息: %s' % (district, road, error_msg))\n",
    "        # print(district + ' ' + road + ' 爬取遇到錯誤' + ' 錯誤訊息：' + error_msg)\n",
    "    \n",
    "   \n",
    "\n",
    "def get_ColumnsData(bs):\n",
    "    # 讀取表格\n",
    "    string = ''\n",
    "    for sibling in bs.find('table', {'id': 'ContentPlaceHolder1_ContentPlaceHolder1_gvTruePrice_A_gv_TruePrice'}).tr.next_siblings:\n",
    "        string = string + str(sibling)\n",
    "\n",
    "    # 解析表格\n",
    "    soup = BeautifulSoup(string, 'html.parser')\n",
    "    content = soup.find_all('tr', {'class': 'gridTable'})\n",
    "\n",
    "    counter = 1\n",
    "    while len(content) > counter:\n",
    "        # 要記錄的資料\n",
    "        District = content[counter].find_all(\n",
    "            'td')[1].get_text()\n",
    "        Adress = content[counter].find_all(\n",
    "            'td')[2].get_text()\n",
    "        Date = content[counter].find_all(\n",
    "            'td')[3].get_text()\n",
    "        TotalPrice = content[counter].find_all(\n",
    "            'td')[4].get_text()\n",
    "        UnitPrice = content[counter].find_all(\n",
    "            'td')[5].get_text()\n",
    "        Garage = content[counter].find_all(\n",
    "            'td')[6].get_text()\n",
    "        BuildingArea = content[counter].find_all(\n",
    "            'td')[7].get_text()\n",
    "        LandArea = content[counter].find_all(\n",
    "            'td')[8].get_text()\n",
    "        BuildingType = content[counter].find_all(\n",
    "            'td')[9].get_text()\n",
    "        HouseAge = content[counter].find_all(\n",
    "            'td')[10].get_text()\n",
    "        Floor = content[counter].find_all(\n",
    "            'td')[11].get_text()\n",
    "        TransactionalType = content[counter].find_all(\n",
    "            'td')[12].get_text()\n",
    "        Note = content[counter].find_all(\n",
    "            'td')[13].get_text()\n",
    "        TransactionRecord = content[counter].find_all(\n",
    "            'td')[14].get_text()\n",
    "\n",
    "        # 將資料存入對應列表中\n",
    "        District_list.append(District)\n",
    "        Adress_list.append(Adress)\n",
    "        Date_list.append(Date)\n",
    "        TotalPrice_list.append(TotalPrice)\n",
    "        UnitPrice_List.append(UnitPrice)\n",
    "        Garage_list.append(Garage)\n",
    "        BuildingArea_list.append(BuildingArea)\n",
    "        LandArea_list.append(LandArea)\n",
    "        BuildingType_list.append(BuildingType)\n",
    "        HouseAge_list.append(HouseAge)\n",
    "        Floor_list.append(Floor)\n",
    "        TransactionalType_list.append(TransactionalType)\n",
    "        Note_list.append(Note)\n",
    "        TransactionRecord_list.append(TransactionRecord)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "def get_RoadList(District):\n",
    "    RoadList = RoadData[District].dropna().tolist()\n",
    "\n",
    "    return RoadList\n",
    "\n",
    "\n",
    "# 匯入路段名稱資料\n",
    "RoadData = pd.read_excel('C:\\\\Users\\\\lol\\\\Desktop\\\\TaipeiTruePriceCrawler-master\\\\路段.xlsx')\n",
    "\n",
    "# 爬蟲模型\n",
    "District_list = []  # 行政區\n",
    "Adress_list = []  # 土地位置或建物門牌\n",
    "Date_list = []  # 交易日期\n",
    "TotalPrice_list = []\n",
    "UnitPrice_List = []\n",
    "Garage_list = []\n",
    "BuildingArea_list = []\n",
    "LandArea_list = []\n",
    "BuildingType_list = []\n",
    "HouseAge_list = []\n",
    "Floor_list = []\n",
    "TransactionalType_list = []\n",
    "Note_list = []\n",
    "TransactionRecord_list = []\n",
    "\n",
    "column = ['行政區', '土地位置或建物門牌', '交易日期', '交易總價(萬元)', '交易單價(萬元/坪)', '單價是否含車位', '建物移轉面積(坪)',\n",
    "          '土地移轉面積(坪)', '建物型態', '屋齡', '樓層別/總樓層', '交易種類', '備註事項', '歷次移轉(含過去移轉資料)']\n",
    "\n",
    "# 設定要搜尋的行政區\n",
    "District_List = ['松山區','大安區','中正區','萬華區','大同區','中山區','文山區','南港區','內湖區','士林區','北投區','信義區']\n",
    "Search_District = '信義區'\n",
    "\n",
    "# 開始爬蟲\n",
    "\n",
    "# 測試用\n",
    "# crawler(district=Search_District, positioning_method='路段', road='和平東路三段', start_year=109, start_month=7, end_year=109, end_month=9)\n",
    "\n",
    "\n",
    "# 此程式是抓單一路段的資料，可以透過迴圈爬取其他路段的資料\n",
    "'''\n",
    "for i in tqdm(get_RoadList(Search_District)):\n",
    "    crawler(district=Search_District, positioning_method='路段', road=i,\n",
    "            start_year=108, start_month=8, end_year=109, end_month=9)\n",
    "    time.sleep(1)\n",
    "'''\n",
    "\n",
    "# 依時間範圍爬取臺北市全區資料\n",
    "def Clawler_by_Time(sy, sm, ey, em):\n",
    "    '''\n",
    "    sy: 起始年\n",
    "    sm: 起始月\n",
    "    ey: 截止年\n",
    "    em: 截止月\n",
    "    '''\n",
    "    for district in tqdm(District_List):\n",
    "        for r in (get_RoadList(district)):\n",
    "            crawler(district=district, positioning_method='路段', road=r,\n",
    "                    start_year=sy, start_month=sm, end_year=ey, end_month=em)\n",
    "            time.sleep(1)\n",
    "    print('全部資料爬取完成')\n",
    "\n",
    "Clawler_by_Time(109, 8, 109, 9)\n",
    "\n",
    "# 將爬下來的資料存入字典\n",
    "ColumnsData = {'行政區': District_list, '土地位置或建物門牌': Adress_list,\n",
    "               '交易日期': Date_list, '交易總價(萬元)': TotalPrice_list,\n",
    "               '交易單價(萬元/坪)': UnitPrice_List, '單價是否含車位': Garage_list,\n",
    "               '建物移轉面積(坪)': BuildingArea_list, '土地移轉面積(坪)': LandArea_list,\n",
    "               '建物型態': BuildingType_list, '屋齡': HouseAge_list,\n",
    "               '樓層別/總樓層': Floor_list, '交易種類': TransactionalType_list,\n",
    "               '備註事項': Note_list, '歷次移轉(含過去移轉資料)': TransactionRecord_list\n",
    "               }\n",
    "\n",
    "\n",
    "AllData = pd.DataFrame(ColumnsData)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# %%\n",
    "# 輸出資料\n",
    "AllData.to_excel('data.xlsx')\n",
    "\n",
    "# %%\n",
    "print(str(7).zfill(2))\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
